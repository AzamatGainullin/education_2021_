{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c7b7c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     Type    Data/Info\n",
      "------------------------------\n",
      "global_url   str     https://realty.yandex.ru/<...>/kvartira/odnokomnatnaya/\n",
      "html         str     <!doctype html><html lang<...>\\n</script></body></html>\n"
     ]
    }
   ],
   "source": [
    "%whos str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20810504",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "y = [1,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e297293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vars():\n",
    "    np.math.acos(2)\n",
    "    csv.DictWriter(html)\n",
    "    sleep(23)\n",
    "    requests.get(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0028555",
   "metadata": {},
   "source": [
    "!pip3 install https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tarball/master\n",
    "!pip3 install jupyter_nbextensions_configurator\n",
    "!jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129dfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from time import sleep\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408d56d",
   "metadata": {},
   "source": [
    "# Парсинг https://wordpress.org/plugins/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd73203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "url = 'https://realty.yandex.ru/moskva/snyat/kvartira/odnokomnatnaya/'\n",
    "html = get_html(url)\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d40fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all('section'))\n",
    "\n",
    "def get_featured_plugins(soup, name='Featured Plugins'):\n",
    "    for section in soup.find_all(\"section\", class_=\"plugin-section\"):\n",
    "        temp = section.find('h2').text\n",
    "        if temp == name:\n",
    "            fp_=section\n",
    "    try:\n",
    "        return fp_\n",
    "    except UnboundLocalError as err:\n",
    "        print('Такого раздела нет, ребята!')\n",
    "        raise err\n",
    "\n",
    "#fp = get_featured_plugins(soup, name='Featured Plugins')\n",
    "\n",
    "def get_data(fp):\n",
    "    sites = []\n",
    "    names = []\n",
    "    ratings = []\n",
    "    fp1 = fp.find_all('h3', class_=\"entry-title\")\n",
    "    fp2 = fp.find_all('div', class_=\"plugin-rating\")\n",
    "    for i in fp1:\n",
    "        sites.append(i.a['href'])\n",
    "        names.append(i.a.string)\n",
    "    for i in fp2:\n",
    "        ratings.append(i.text)\n",
    "    return (sites, names, ratings)\n",
    "\n",
    "\n",
    "\n",
    "#data = get_data(fp)\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "# with open('./file.csv', \"w\", newline=\"\\n\") as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6024a9",
   "metadata": {},
   "source": [
    "#### Способ построения дерева разметки и запроса для поиска без обзора визуального"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00233dfd",
   "metadata": {},
   "source": [
    "Сначала идентифицируем ту единицу поиска, которая одна из многих. Визуально, потом построения запроса как получится:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67848a77",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0641b8dc39dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"section\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"plugin-section\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://wordpress.org/plugins/classic-editor/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "child = soup.find_all(\"section\", class_=\"plugin-section\")[1].find('a', href=\"https://wordpress.org/plugins/classic-editor/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71648f4c",
   "metadata": {},
   "source": [
    "Потом выводим полный путь родителей - путь наверх:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7a1bd8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'child' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a2e20612cd2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'child' is not defined"
     ]
    }
   ],
   "source": [
    "for parent in child.parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8757cf5",
   "metadata": {},
   "source": [
    "То же самое проделаем для второй единицы поиска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d11eb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "child1 = soup.find_all(\"section\", class_=\"plugin-section\")[2].find('a', href=\"https://wordpress.org/plugins/gutenberg/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "441dff3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div\n",
      "article\n",
      "section\n",
      "main\n",
      "div\n",
      "div\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "for parent in child1.parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ccac54",
   "metadata": {},
   "source": [
    "Мы видим, что пути пересекаются на уровне section. Еще более важная информация заключается в том, что после section нижеследующий тег для поиска - article.\n",
    "Попробуем выделить нашу единицу поиска уже путем подстановки article и уже визуального анализа разметки, что теперь легко сделать ввиду размерности разметки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "20001374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wordpress.org/plugins/gutenberg/'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"section\", class_=\"plugin-section\")[2].find_all('article')[0].find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b3686b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wordpress.org/plugins/gutenberg/'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"section\", class_=\"plugin-section\")[2].find_all('article')[0].h3.find('a')['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069bcc9e",
   "metadata": {},
   "source": [
    "Вот и все. Теперь задача поиска сайтов плагинов сводится к написанию итератора for i in ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73af0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = soup.find_all(\"section\", class_=\"plugin-section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "09caa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "spisok = []\n",
    "for section in sections:\n",
    "    articles = section.find_all('article')\n",
    "    for article in articles:\n",
    "        #temp = article.find('a')['href']\n",
    "        temp = article.h3.find('a')['href']\n",
    "        if article.h3.find('a').text!=None:\n",
    "            spisok.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1520d3",
   "metadata": {},
   "source": [
    "# Парсинг https://coinmarketcap.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61519c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "url = 'https://coinmarketcap.com/'\n",
    "html = get_html(url)\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93b5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trows = soup.tbody.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b544dbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/currencies/bitcoin/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trows[0].a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9f5679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bitcoin1BTC'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trows[0].a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8edef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in trows:\n",
    "    href = row.a['href']\n",
    "    name = row.a.text\n",
    "    data.append((href, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd3244",
   "metadata": {},
   "source": [
    "#### Хотя можно было так, намного эффективнее, перебор по тегам td:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8f12a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "trows = soup.tbody.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fe7aa78e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td><span></span></td>,\n",
       " <td><span></span></td>,\n",
       " <td><a class=\"cmc-link\" href=\"/currencies/solana/\"><span class=\"circle\"></span><span>Solana</span><span class=\"crypto-symbol\">SOL</span></a></td>,\n",
       " <td><span>$<!-- -->26.78</span></td>,\n",
       " <td><span></span></td>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = trows[17].find_all('td')\n",
    "tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3db878c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/currencies/solana/'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[2].a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "46d2bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$26.78'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[3].find('span').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d8aa0",
   "metadata": {},
   "source": [
    "#### РЕГУЛЯРНОЕ ВЫРАЖЕНИЕ ПРИМЕНЕНО!!! СМ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8a70421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"price___3rj7O\"><a class=\"cmc-link\" href=\"/currencies/cardano/markets/\">$1.39</a></div>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trows[4].find_all('div', class_=re.compile(\"price\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956487a8",
   "metadata": {},
   "source": [
    "# Парсинг рубрикатора Яндекса. 2990 объявлений показывает\n",
    "написать функцию которая удаляет \\xa0 и заменяет пробелом, на уровне переменной html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf86e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "global_url = 'https://realty.yandex.ru/moskva/snyat/kvartira/odnokomnatnaya/'\n",
    "\n",
    "### МОДИФИЦИРУЕМ ОБРАЩЕНИЕ К САЙТУ, НА СЛУЧАЙ ЕСЛИ ЗАБАНЯТ\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    if r.ok:\n",
    "        return r.text\n",
    "    else:\n",
    "        print(r.status_code)\n",
    "        \n",
    "###    \n",
    "\n",
    "def get_soup(html):\n",
    "    html1=html.encode('l1').decode()\n",
    "    soup = BeautifulSoup(html1, 'lxml')\n",
    "    return soup\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('arenda.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow([data['space'],\n",
    "                         data['metro'],\n",
    "                         data['price'],\n",
    "                         data['description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9e50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_page(url):\n",
    "    html = get_html(url)\n",
    "    soup = get_soup(html)\n",
    "    page_offers = soup.find_all('li', class_='OffersSerpItem OffersSerpItem_view_desktop OffersSerpItem_format_full OffersSerp__list-item OffersSerp__list-item_type_offer')\n",
    "    for offer in offers:\n",
    "        space = offer.find('h3', class_='OffersSerpItem__title').text\n",
    "        metro = offer.find('span', class_='MetroStation').text\n",
    "        price = offer.find('span', class_='price').text\n",
    "        description = offer.find('p', class_='OffersSerpItem__description').text\n",
    "        data = {'space': space,\n",
    "               'metro': metro,\n",
    "               'price': price,\n",
    "               'description': description}\n",
    "        #print(data)\n",
    "        write_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b135636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(global_url):\n",
    "    pages = range(30,100)\n",
    "    for page in pages:\n",
    "        url = global_url + '?page=' + str(page)\n",
    "        time.sleep(random.randint(1,10))\n",
    "        get_data_from_page(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3a0ee",
   "metadata": {},
   "source": [
    "###### НАДО СОЗДАТЬ СНАЧАЛА ФАЙЛ:\n",
    "with open('arenda.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['space', 'metro', 'price', 'description'])\n",
    "\n",
    "###### ПОТОМ ЗАПУСК:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa5a3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(global_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1da70f",
   "metadata": {},
   "source": [
    "###### МОЖНО ОРГАНИЗОВАТЬ ЦИКЛ  WHILE, ПОКА ЕСТЬ КНОПКА \"следующая\":  (в конце break можно использовать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ff68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = get_html(global_url)\n",
    "soup = get_soup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c32b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"Pager__radio-link\" href=\"/moskva/snyat/kvartira/odnokomnatnaya/?page=1\">Следующая<i class=\"Icon Icon_type_arrow Icon Icon_direction_right Icon_animate-direction Pager__next-arrow\"><svg viewbox=\"0 0 9 5\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"shape\" d=\"M4.5 3.7L.7 0 0 .7 4.5 5 9 .7 8.3 0z\"></path></svg></i></a>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(string=re.compile('Следующая')).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa5f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0e0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de4088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fead36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd74b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5232e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2aa10a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a', class_='Pager__radio-link')[-1].text=='Следующая'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea37d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if (random.randint(1,100000) + random.randint(1,100000)) == 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67dff2a",
   "metadata": {},
   "source": [
    "###### ВОТ ЧТО ДАВНО ИСКАЛИ. ЕСЛИ ЕСТЬ ФРАГМЕНТ ТЕКСТА НА СТРАНИЦЕ, ЛЕГКО УЗНАТЬ К КАКОМУ ТЕГУ ОН ПРИНАДЛЕЖИТ, ДА И ВООБЩЕ ВСЕХ PARENTS НАЙТИ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ed716bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"Pager__radio-link\" href=\"/moskva/snyat/kvartira/odnokomnatnaya/?page=21\">Следующая<i class=\"Icon Icon_type_arrow Icon Icon_direction_right Icon_animate-direction Pager__next-arrow\"><svg viewbox=\"0 0 9 5\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"shape\" d=\"M4.5 3.7L.7 0 0 .7 4.5 5 9 .7 8.3 0z\"></path></svg></i></a>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(string=re.compile('Следующая')).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27b4cedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"Button__text\"><a class=\"Pager__radio-link\" href=\"/moskva/snyat/kvartira/odnokomnatnaya/?page=21\">Следующая<i class=\"Icon Icon_type_arrow Icon Icon_direction_right Icon_animate-direction Pager__next-arrow\"><svg viewbox=\"0 0 9 5\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"shape\" d=\"M4.5 3.7L.7 0 0 .7 4.5 5 9 .7 8.3 0z\"></path></svg></i></a></span>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(string=re.compile('Следующая')).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f175c82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<button class=\"Button Button_js_inited Button_size_m Button_theme_islands Button_type_button\" type=\"button\"><span class=\"Button__text\"><a class=\"Pager__radio-link\" href=\"/moskva/snyat/kvartira/odnokomnatnaya/?page=21\">Следующая<i class=\"Icon Icon_type_arrow Icon Icon_direction_right Icon_animate-direction Pager__next-arrow\"><svg viewbox=\"0 0 9 5\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"shape\" d=\"M4.5 3.7L.7 0 0 .7 4.5 5 9 .7 8.3 0z\"></path></svg></i></a></span></button>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(string=re.compile('Следующая')).parent.parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3dfcb",
   "metadata": {},
   "source": [
    "###### ЯРКИЙ ПРИМЕР. МЫ ВИДИМ НА СТРАНИЦЕ, ЧТО ОДНА ИЗ КВАРТИР НАХОДИТСЯ В МЕДВЕДКОВО. МЫ ДОБАВЛЯЕМ ПОСТЕПЕННО .PARENT.TEXT И СМОТРИМ, ЧТОБЫ НАЧАЛИ ОТПЕЧАТЫВАТЬСЯ ВСЕ КВАРТИРЫ. ПОТОМ .TEXT УБИРАЕМ И ПИШЕМ СЛЕДУЮЩИЙ КОД, КОГДА НАШЛИ САМЫЙ РОДИТЕЛЬСКИЙ ДЛЯ ВСЕХ КВАРТИР PARENT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00aa489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flats = soup.find(string=re.compile('Медведково')).parent.parent.parent.parent.parent.parent.parent.parent.parent.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "for flat in flats:\n",
    "    print(flat.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d3893",
   "metadata": {},
   "source": [
    "+ 1237,8 м², 1-комнатная11 этаж из 14проезд Шокальского, 35Медведково 13 мин.31 000 ₽ / мес.от Яндекс.АрендыПроверено в Росреестре?Квартира сдаётся с Яндекс.Арендой, а значит все для вас: - без залога - без единоразовой комиссии - с поддержкой от наших специалистов в процессе проживания Мы можем показать вам квартиру онлайн - благодаря уникальному 3Д туру - это также детально,Показать телефонВ избранноеЯндекс.Аренда, сервис Яндекса6 минут назад\n",
    "+ 440 м², 1-комнатная3 этаж из 12Ботанический переулок, 5Проспект Мира 8 мин.120 000 ₽ / мес.?ID 32519 Апартаменты в стиле модерн в отеле \"Гарден\" на охраняемой территории Ботанического сада. Апартаменты созданы для длительного проживания с максимальным комфортом и станут идеальным местом для проживания в долгосрочных командировках иПоказать телефонВ избранноеSavills, агентство5 часов назад\n",
    "+ 1520 м², 1-комнатнаяЖК «Атмосфера», 1 этаж из 14Совхозная улица, 8БЛюблино 10 мин.30 000 ₽ / мес.?Отличная студия в ЛюблиноПоказать телефонВ избранноеАН \"SANDI\", агентство4 часа назад\n",
    "+ и так далее..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfedb8c5",
   "metadata": {},
   "source": [
    "#### РЕГУЛЯРНЫЕ ВЫРАЖЕНИЯ. PYTHEX.ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f05ea",
   "metadata": {},
   "source": [
    "\\d{1,9} - любое количество только цифр. диапазон цифр - от 1 до 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary(s):\n",
    "    # salary: 2700 usd per month\n",
    "    pattern = r'\\d{1,9}'\n",
    "    # salary = re.findall(pattern, s)[0]\n",
    "    print(salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce481682",
   "metadata": {},
   "source": [
    "    # СПРАВОЧНИК НАИБОЛЕЕ ЧАСТО ПРИМЕНЯЕМЫХ СИМВОЛОВ В РЕГУЛЯРНЫХ ВЫРАЖЕНИЯХ:\n",
    "    # ^ - начало строки\n",
    "    # $ - конец строки\n",
    "    # . - любой символ\n",
    "    # + - неограниченное количество вхождений\n",
    "    # '\\d' - цифра\n",
    "    # '\\w' - буквы, цифры, _\n",
    "    # {1,9} - количество вхождений от 1 до 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a92be",
   "metadata": {},
   "source": [
    "ПРИМЕР:   '^@\\w+'   - слово начинается на @ (аккаунты допустим), потом идут любые буквы, цифры в неограниченном количестве.\n",
    "Или ниже - слова на букву М, число букв/цифр потом от 6 до 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2318bf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Монолитный',\n",
       " 'Медведково',\n",
       " 'Москворечье',\n",
       " 'Московская область',\n",
       " 'Марксистская',\n",
       " 'Марьина роща',\n",
       " 'Марьино',\n",
       " 'Маяковская',\n",
       " 'Медведково',\n",
       " 'Международная',\n",
       " 'Менделеевская',\n",
       " 'Минская',\n",
       " 'Мичуринский проспект',\n",
       " 'Мнёвники',\n",
       " 'Молодёжная',\n",
       " 'Москворечье',\n",
       " 'Мякинино',\n",
       " 'Марушкинское',\n",
       " 'Марфино',\n",
       " 'Марьина Роща',\n",
       " 'Марьино',\n",
       " 'Матушкино',\n",
       " 'Метрогородок',\n",
       " 'Мещанский',\n",
       " 'Михайлово-Ярцевское',\n",
       " 'Можайский',\n",
       " 'Молжаниновский',\n",
       " 'Москворечье-Сабурово',\n",
       " 'Московский',\n",
       " 'Мосрентген',\n",
       " 'Московская область',\n",
       " 'Магаданская область',\n",
       " 'Мордовия',\n",
       " 'Мурманская область',\n",
       " 'Мобильная версия']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=re.compile('^М\\w{6,12}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96450149",
   "metadata": {},
   "source": [
    "# ЗАПИСЬ С ПАРСИНГА В БАЗУ ДАННЫХ POSTGRESQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a49e4",
   "metadata": {},
   "source": [
    "Первоначальные настройки POSTGRESQL для начала работы в PGAdmin4.\n",
    "Первый раз будем логиниться от имени создаваемого системного юзера postgres, при настройках по-умолчанию для него используется авторизация типа peer, никакого пароля постгре не запросит:\n",
    " * $ sudo -u postgres psql\n",
    "\n",
    "Далее уже в оболочке постгреса (куда вы должны попасть после предыдущей команды) выполним смену пароля пользователя:\n",
    " * $ \\password postgres\n",
    "-- введите новый пароль (скорее всего дважды). У меня будет цифра 1.\n",
    "\n",
    "Создание базы данных (название test): # если не работает, вводить руками, не копировать #\n",
    " * $ CREATE DATABASE test;\n",
    "\n",
    "Просмотр всех имеющихся баз данных:\n",
    " * $ \\l\n",
    "\n",
    "Выходим из постгре:\n",
    " * $ \\q\n",
    " \n",
    "Или выходим из оболочки постгре командой:\n",
    " * $ exit\n",
    "\n",
    "Пакеты, в том числе ORM, необходимые для работы кода ниже:\n",
    " * $  pip install peewee psycopg2 psycopg2-binary\n",
    "\n",
    "Чтобы сделать дамп (файл базы данных для передачи заинтересованным лицам):\n",
    " * $ pg_dump -U postgres -h localhost test > coins.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from peewee import *\n",
    "\n",
    "\n",
    "#file = open('.cmc.csv')\n",
    "FILENAME = \"./help_files/cmc.csv\"\n",
    "\n",
    "### ВАЖНО: db как шаблон ПОДСОЕДИНЕНИЯ К УЖЕ СУЩЕСТВУЮЩЕЙ БАЗЕ test\n",
    "db = PostgresqlDatabase(database='test', user='postgres',\n",
    "password='1', host='localhost')\n",
    "\n",
    "class Coin(Model):\n",
    "    name = CharField()\n",
    "    url = TextField()\n",
    "    price = CharField()\n",
    "\n",
    "    class Meta:\n",
    "        database = db\n",
    "\n",
    "def main():\n",
    "    db.connect()\n",
    "    db.create_tables([Coin])\n",
    "    with open(FILENAME, \"r\") as f:\n",
    "        order = ['name', 'url', 'price']\n",
    "        reader = csv.DictReader(f, fieldnames=order)\n",
    "        coins = list(reader)\n",
    "        # 1 способ\n",
    "        # for row in coins:\n",
    "        #     coin = Coin(name=row['name'],\n",
    "        #     url=row['url'], price=row['price'])\n",
    "        #     coin.save()\n",
    "\n",
    "        # 2 способ\n",
    "        # with db.atomic():\n",
    "        #     for row in coins:\n",
    "        #         Coin.create(**row)\n",
    "\n",
    "        # 3 способ, самый быстрый, пакетами запись\n",
    "        with db.atomic():\n",
    "            for index in range(0, len(coins), 100):\n",
    "                Coin.insert_many(coins[index:index+100]).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329fbb7",
   "metadata": {},
   "source": [
    "# 08 Парсинг данных подгружаемых через AJAX часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4b7d7",
   "metadata": {},
   "source": [
    "Если при пагинации сайта, например https://www.liveinternet.ru/rating/ru/, смена страницы не влечет изменение адресной строки (так работает технология AJAX, когда JS отправляет на сервер запрос только текста для новой страницы для перехода, не перезагружает страницу целиком), заходим в инспектор кода страницы, потом:\n",
    " * вкладка Network страницы;\n",
    " * вкладка XHR\n",
    " * на самом сайте в пагинации страницы нажимаем номер следующей страницы\n",
    " * и в поле Name появляется другая ссылка, на которую собственно сайт и перешел. Адресная строка прежняя\n",
    " * видим в поле Response ответ сервера. Копируем эту настоящую ссылку из поля name и уже дальше ее и анализируем\n",
    " * в коде ниже мы работает с этой ссылкой, она возвращает просто текст, не объект Soup\n",
    " * поэтому работаем уже как с текстом - очищаем от пробелов, разбиваем по переносу строки и т.п.\n",
    " * по количеству страниц на сайте делаем цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4a4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('websites.csv', 'a') as f:\n",
    "        order = ['name', 'url', 'description', 'traffic', 'percent']\n",
    "        writer = csv.DictWriter(f, fieldnames=order)\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    for i in range(0, 20): # здесь было 6428 страниц, убрал. говорят цикл до конца работает\n",
    "        url = 'https://www.liveinternet.ru/rating/ru//today.tsv?page={}'.format(str(i))\n",
    "        response = get_html(url)\n",
    "        data = response.strip().split('\\n')[1:]\n",
    "\n",
    "        for row in data:\n",
    "            columns = row.strip().split('\\t')\n",
    "            name = columns[0]\n",
    "            url = columns[1]\n",
    "            description = columns[2]\n",
    "            traffic = columns[3]\n",
    "            percent = columns[4]\n",
    "\n",
    "            data = {'name': name,\n",
    "                    'url': url,\n",
    "                    'description': description,\n",
    "                    'traffic': traffic,\n",
    "                    'percent': percent}\n",
    "            write_csv(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4ef82",
   "metadata": {},
   "source": [
    "#### Примечание. Например, по адресу https://www.liveinternet.ru/stat/AIF/ (статистика для сайта Аиф, переход с рейтинга по ссылке) видно кучу информации для сайта Аиф:\n",
    "(В отчете представлены общие показатели посещаемости сайта за сутки. Можно видеть за неделю, месяц и т.д.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff0d17",
   "metadata": {},
   "source": [
    "Можно подумать, как спарсить дополнительно все это, это же будет огромная база данных, возможно применить машинное обучение и какие-то интересные выводы по Рунету... Идеи:\n",
    "* Прогноз рейтинга сайта через неделю, месяц и т.д. В зависимости от этих вышеперечисленных фич по дням/неделям"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4f093",
   "metadata": {},
   "source": [
    "Там наверху есть отбор по категориям сайтов - спорт, обучение и т.п. Подумать надо тематическим отбором"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a256b6",
   "metadata": {},
   "source": [
    "# 09 Парсинг данных в несколько процессов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb012dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from multiprocessing import Pool\n",
    "from time import sleep\n",
    "\n",
    "def get_html(url):\n",
    "    # sleep(1)\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('websites.csv', 'a') as file:\n",
    "        order = ['name', 'url', 'description', 'traffic', 'percent']\n",
    "        writer = csv.DictWriter(file, fieldnames=order)\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "def get_page_data(text):\n",
    "        data = text.strip().split('\\n')[1:]\n",
    "\n",
    "        for row in data:\n",
    "            columns = row.strip().split('\\t')\n",
    "            name = columns[0]\n",
    "            url = columns[1]\n",
    "            description = columns[2]\n",
    "            traffic = columns[3]\n",
    "            percent = columns[4]\n",
    "\n",
    "            data = {'name': name,\n",
    "                    'url': url,\n",
    "                    'description': description,\n",
    "                    'traffic': traffic,\n",
    "                    'percent': percent}\n",
    "            write_csv(data)\n",
    "\n",
    "\n",
    "def make_all(url):\n",
    "    text = get_html(url)\n",
    "    get_page_data(text)\n",
    "\n",
    "\n",
    "def main():\n",
    "    #6320\n",
    "\n",
    "    # ИЗЯЩНО ПОЛУЧИЛИ СПИСОК ВЕБ-СТРАНИЦ\n",
    "    url = 'https://www.liveinternet.ru/rating/ru//today.tsv?page={}'\n",
    "    urls = [url.format(str(i)) for i in range(1, 6321)]\n",
    "\n",
    "    with Pool(20) as p:\n",
    "        p.map(make_all, urls)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70c309",
   "metadata": {},
   "source": [
    "Мультипроцессинг хоть и должен был по идее увеличить скорость парсинга в 20 раз (with Pool(20)), такого быстродействия не наблюдалось. Скорее всего сервер ограничивает с одного IP такой траффик, по словам автора кода"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8655e2d",
   "metadata": {},
   "source": [
    "# 10 Парсинг данных, подгружаемых с помощью JQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6a62a",
   "metadata": {},
   "source": [
    "Если страница при прокручивании вниз не заканчивается, а продолжает подгружаться, то это работа JQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9731de2",
   "metadata": {},
   "source": [
    "Как парсить? По аналогии с Ajax - смотрим при инспекте страницы не elements, а вкладку Network и там уже XHR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d3b11",
   "metadata": {},
   "source": [
    "Ан нет. Requests при обращении к этим скрытым страницам возвращает код 403 - доступ запрещен...\n",
    "Нам не хватает user agent (нашего браузера), который указывается в request headers.\n",
    "\n",
    "Точнее так. В requests много параметров которые можно регулировать. Обычно начинают с подбора user agent, а дальше как пойдет... надо смотреть что там еще в в request headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def get_html(url):\n",
    "    print(url)\n",
    "    user_agent = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "    r = requests.get(url, headers=user_agent)\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('testimonials.csv', 'a') as f:\n",
    "        order = ['author', 'since']\n",
    "        writer = csv.DictWriter(f, fieldnames=order)\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "def get_articles(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    ts = soup.find('div', class_='testimonial-container').find_all('article')\n",
    "    return ts # [] or [a,b,s] - РЕАЛИЗОВАНО ХОРОШО. ЕСЛИ СПИСОК ПУСТОЙ, ЗНАЧИТ СТАТЕЙ НА ТЕКУЩЕЙ СТРАНИЦЕ НЕТ.\n",
    "                                # ТОГДА ЭТО СЫГРАЕТ РОЛЬ В ЦИКЛЕ WHILE: BREAK ЦИКЛ ОСТАНОВИТ\n",
    "\n",
    "def get_page_data(ts):\n",
    "    for t in ts:\n",
    "        try:\n",
    "            since = t.find('p', class_='traxer-since').text.strip()\n",
    "        except:\n",
    "            since = ''\n",
    "        try:\n",
    "            author = t.find('p', class_='testimonial-author').text.strip()\n",
    "        except:\n",
    "            author = ''\n",
    "        data = {'author': author, 'since': since}\n",
    "        write_csv(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1. Получение контейнера с отзывами и списка отзывов\n",
    "    # 2. Если список есть, то парсим отзывы\n",
    "    # 3. Если список пустой - цикл прерывается\n",
    "    page = 1\n",
    "    while True:\n",
    "        #page = 1 ЗДЕСЬ АВТОР ОШИБСЯ. Я ПЕРЕНЕС ВЫРАЖЕНИЕ УРОВНЕМ ВЫШЕ. ИНАЧЕ ЦИКЛ БЕСКОНЕЧНО БЕГАЕТ ПО page = 1\n",
    "        url = 'https://catertrax.com/why-catertrax/traxers/page/{}/'.format(str(page))\n",
    "\n",
    "        articles = get_articles(get_html(url)) # [] or [1,2,3]\n",
    "\n",
    "        if articles:\n",
    "            get_page_data(articles)\n",
    "            page = page + 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348700a",
   "metadata": {},
   "source": [
    "# 11 Парсинг ютюба"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67c894",
   "metadata": {},
   "source": [
    "Важное замечание. Requests не обрабатывает Javascript. **Здесь идет мощная обработка ответов requests**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58af7ac",
   "metadata": {},
   "source": [
    "Здесь примечательно, что иницируется нажатие кнопки **\"ЕЩЕ\"**. Возвращается JSON-объект, и в теге/классе ответа содержится новая ссылка с видео"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6e5d3",
   "metadata": {},
   "source": [
    "Если не получается обрабатывать такие случаи вытягивающихся страниц, можно спросить других спецов. Нанять один раз, и все.\n",
    " * Пишут на сайтах что нужен Selenium для обработки JS.\n",
    "  * https://qna.habr.com/q/236162 Нужен пишут Selenium, PhantomJS\n",
    " * https://newtechaudit.ru/veb-skraping-request-html/  - requests_html умеет парсить JS скрипты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0078f40",
   "metadata": {},
   "source": [
    "Ниже код автора, у него свой случай, код уже не работает, в ютюбе нет кнопки еще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a27983b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('videos.csv', 'a') as f:\n",
    "        order = ['name', 'url']\n",
    "        writer = csv.DictWriter(f, fieldnames=order)\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "def get_page_data(response):\n",
    "    if 'html' in response.headers['Content-Type']:\n",
    "        html = response.text\n",
    "    else:\n",
    "        html = response.json()['content_html']\n",
    "\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    items = soup.find_all('h3', class_='yt-lockup-title')\n",
    "\n",
    "    for item in items:\n",
    "        name = item.text.strip()\n",
    "        url = item.find('a').get('href')\n",
    "\n",
    "        data = {'name': name, 'url': url}\n",
    "        write_csv(data)\n",
    "\n",
    "\n",
    "def get_next(response):\n",
    "    if 'html' in response.headers['Content-Type']:\n",
    "        html = response.text\n",
    "    else:\n",
    "        html = response.json()['load_more_widget_html']\n",
    "\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    try:\n",
    "        url = 'https://youtube.com' + soup.find('button', class_='load-more-button').get('data-uix-load-more-href')\n",
    "    except:\n",
    "        url = ''\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "def main():\n",
    "    # url = 'https://www.youtube.com/browse_ajax?action_continuation=1&direct_render=1&continuation=4qmFsgJAEhhVQ09tNF9BbkxQTEVCVnJiby0tTjdrUEEaJEVnWjJhV1JsYjNNZ0FEZ0JZQUZxQUhvQk1yZ0JBQSUzRCUzRA%253D%253D'\n",
    "    url = 'https://www.youtube.com/user/coolpropaganda/videos'\n",
    "    # get_page_data(get_html(url))\n",
    "\n",
    "    while True:\n",
    "        response = get_html(url)\n",
    "        get_page_data(response)\n",
    "\n",
    "        url = get_next(response)\n",
    "\n",
    "        if url:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5764a",
   "metadata": {},
   "source": [
    "Поэкспериментирую с requests-html, он помогает вытащить все ссылки со страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa316da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession  \n",
    "session = HTMLSession()  \n",
    "r = session.get('https://www.exler.ru/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f59173b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.exler.ru/blog/vot-tebe-i-rossiyskiye-turisty.htm#comments',\n",
       " 'https://www.exler.ru/ezhe/gorod-terrasa-dva-interesnejshih-osobnyaka-i-zamok-s-muzeem.htm#comments',\n",
       " 'https://www.exler.ru/books/Exler%20-%20EPUB.zip',\n",
       " 'https://www.exler.ru/blog/',\n",
       " 'https://www.exler.ru/dieta/',\n",
       " 'https://www.exler.ru/expromt/obzor-smartfona-xiaomi-mi-9-ubijca-li-on-flagmanov.htm',\n",
       " 'https://www.exler.ru/info/firsttime.htm',\n",
       " 'https://www.exler.ru/aliexpress/delimsya-nahodkami-iz-kitajskih-magazinov-39.htm',\n",
       " 'https://www.exler.ru/ezhe/studiya-dzhejmsa-kemerona-ili-kak-sozdavalsya-avatar.htm#comments',\n",
       " 'https://www.exler.ru/blog/yeshche-odno-nezavisimoye-smi-v-rossii-zakryvayetsya.htm#comments']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(r.html.absolute_links)[-10:] # сократил выдачу, там много"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db155515",
   "metadata": {},
   "source": [
    "# 12 Используем прокси"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebf5d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from random import choice\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ec383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxy():\n",
    "    html = requests.get('https://free-proxy-list.net/').text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    trs = soup.find('table', id='proxylisttable').find_all('tr')[1:20]\n",
    "    proxies = []\n",
    "\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        ip = tds[0].text.strip()\n",
    "        port = tds[1].text.strip()\n",
    "        schema = 'https' if 'yes' in tds[6].text.strip() else 'http' # влияет от ресурса, который будем парсить\n",
    "        proxy = {'schema': schema, 'address': ip + ':' + port}\n",
    "        proxies.append(proxy)\n",
    "\n",
    "    # return choice(proxies) ВАРИАНТ АВТОРА. ПОМЕНЯЛ, Т.К. МОЖНО ПРОСТО ЗАПИСАТЬ ВЕСЬ ПЕРЕЧЕНЬ, НЕ ОБНОВЛЯТЬ\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ae667",
   "metadata": {},
   "source": [
    "Разовая операция парсинга и записи в файл данных прокси-серверов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3305ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = get_proxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52ea874",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proxies_file.csv', 'a') as f:\n",
    "    order = ['schema', 'address']\n",
    "    writer = csv.DictWriter(f, fieldnames=order)\n",
    "    for proxy in proxies:\n",
    "        writer.writerow(proxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c76d8",
   "metadata": {},
   "source": [
    "Считали данные из файла обратно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f64f3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proxies_file.csv', \"r\") as f:\n",
    "    order = ['schema', 'address']\n",
    "    reader = csv.DictReader(f, fieldnames=order)\n",
    "    proxies2 = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19ade2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schema': 'http', 'address': '45.33.104.134:80'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice(proxies2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b6fa2",
   "metadata": {},
   "source": [
    "Проверяем на ресурсе, который показывает IP компьютера. Каждый раз он будет у нас разный:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59ba106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url, proxies2):\n",
    "    # proxies = {'https': 'ipaddress:5000'}\n",
    "    # p = get_proxy() # {'schema': '', 'address': ''}\n",
    "    p = choice(proxies2)\n",
    "    proxy = { p['schema']: p['address']  }\n",
    "    r = requests.get(url, proxies=proxy, timeout=10)\n",
    "    return r\n",
    "    #return r.json()['origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffd0c3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [503]>\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    url = 'http://lenta.ru'\n",
    "    print(get_html(url, proxies2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8bded4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http': '5.252.161.48:8080'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = choice(proxies2)\n",
    "proxy = { p['schema']: p['address']  }\n",
    "proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da290bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e9139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2da803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 291,
   "position": {
    "height": "313px",
    "left": "748px",
    "right": "20px",
    "top": "159px",
    "width": "450px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
